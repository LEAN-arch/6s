# six_sigma/data/session_state_manager.py
"""
Manages the application's session state, acting as an in-memory data source
for global manufacturing quality operations.

This module provides the SessionStateManager class, which initializes a rich,
interconnected, and realistic mock dataset reflecting the responsibilities of a
Quality Optimization Engineer Lead. The data model is generated by a separate,
dedicated function to simulate data from multiple sites, product lines, and
ongoing improvement initiatives.

SME Overhaul:
- Added a sophisticated Central Composite Design (CCD) dataset for RSM.
- Enriched product release data with specific failure categories for COPQ analysis.
- Increased the realism of process data shifts.
"""

import logging
import random
from datetime import date, timedelta
from typing import Any, Dict, List, Optional
import streamlit as st
import numpy as np
import pandas as pd

logger = logging.getLogger(__name__)

def _create_quality_optimizer_model(version: int) -> Dict[str, Any]:
    """
    Generates the complete, interconnected mock dataset for the Six Sigma Quality
    Command Center. This model simulates a multi-site manufacturing environment.
    """
    # --- Base Configuration ---
    np.random.seed(42)
    random.seed(42)
    base_date = date.today() - timedelta(days=365)
    sites = ["Eindhoven, NL", "Andover, US", "Shanghai, CN"]
    products_by_site = {
        "Eindhoven, NL": ["IntelliVue Patient Monitor", "Zenition C-arm"],
        "Andover, US": ["IntelliVue Patient Monitor", "HeartStart Defibrillator"],
        "Shanghai, CN": ["Zenition C-arm", "Affiniti Ultrasound"]
    }

    # --- 1. Generate Historical KPI Data ---
    kpi_data = []
    for i in range(365):
        current_date = base_date + timedelta(days=i)
        for site in sites:
            for product in products_by_site[site]:
                improvement_factor = (1 - (i / 730))
                copq_base = 50000 if "Monitor" in product else 75000
                ftr_base = 0.92 if "NL" in site else 0.88
                kpi_data.append({
                    "date": current_date,
                    "site": site,
                    "product_line": product,
                    "copq": int(copq_base * improvement_factor * (1 + np.random.uniform(-0.1, 0.1))),
                    "ftr_rate": ftr_base * improvement_factor * (1 + np.random.uniform(-0.02, 0.02)),
                    "scrap_rate": (1 - (ftr_base * improvement_factor)) * (1 + np.random.uniform(-0.1, 0.1))
                })

    # --- 2. Generate Process Data for DMAIC Analysis ---
    process_data_df = pd.DataFrame({
        'timestamp': pd.to_datetime(pd.date_range(start=base_date, periods=200, freq='D')),
        'voltage_a': np.random.normal(5.0, 0.05, 200),
        'pressure_b': np.random.normal(100, 2.5, 200),
        'seal_temperature': np.random.normal(150, 1.2, 200)
    })
    process_data_df.loc[100:, 'voltage_a'] += 0.1 # Process shift

    # --- 3. Generate Sophisticated DOE/RSM Data (CCD) ---
    alpha = 1.682  # Face-centered CCD alpha for 3 factors
    doe_points = []
    for i in [-1, 1]:
        for j in [-1, 1]:
            for k in [-1, 1]:
                doe_points.append([i, j, k]) # Factorial points
    # Axial points
    for i in [-alpha, alpha]: doe_points.extend([[i, 0, 0], [0, i, 0], [0, 0, i]])
    # Center points
    for _ in range(6): doe_points.append([0, 0, 0])
    doe_df = pd.DataFrame(doe_points, columns=['temp_coded', 'time_coded', 'pressure_coded'])
    
    # Map coded units to real-world values
    doe_df['temperature'] = 150 + doe_df['temp_coded'] * 10
    doe_df['duration_sec'] = 60 + doe_df['time_coded'] * 15
    doe_df['pressure_psi'] = 80 + doe_df['pressure_coded'] * 5
    
    # Simulate a response with curvature and interaction
    noise = np.random.normal(0, 0.5, len(doe_df))
    doe_df['bond_strength'] = (
        85 
        - 2.5 * (doe_df['temp_coded'] - 0.2)**2 
        - 1.5 * doe_df['time_coded']**2 
        - 1.0 * (doe_df['pressure_coded'] + 0.1)**2 
        + 2.0 * doe_df['temp_coded'] * doe_df['time_coded'] 
        + noise
    )

    # --- 4. Define DMAIC Projects ---
    dmaic_projects = [
        {"id": "DMAIC-001", "site": "Andover, US", "product_line": "HeartStart Defibrillator", "title": "Reduce Capacitor Charging Failures", "phase": "Analyze", "problem_statement": "The final test failure rate for the capacitor charging module is 12%, significantly above the 4% target, leading to high scrap costs and rework.", "goal_statement": "Reduce the capacitor charging failure rate from 12% to less than 4% by Q4, resulting in an estimated annual COPQ saving of $250k.", "team": ["John Smith (Lead)", "Jane Doe (Engineer)", "Mike Ross (Ops)"], "start_date": base_date + timedelta(days=180)},
        {"id": "DMAIC-002", "site": "Eindhoven, NL", "product_line": "Zenition C-arm", "title": "Improve X-Ray Tube Alignment Yield (FTR)", "phase": "Improve", "problem_statement": "The First Time Right for the X-ray tube alignment process is 85%, requiring significant rework impacting cycle time.", "goal_statement": "Increase the FTR for X-ray tube alignment to >95% by year-end, reducing cycle time by 8 hours per unit.", "team": ["Elena Reyes (Lead)", "Ben Carter (SME)"], "start_date": base_date + timedelta(days=90)},
        {"id": "DMAIC-003", "site": "Eindhoven, NL", "product_line": "IntelliVue Patient Monitor", "title": "Optimize Display Module Bonding Process", "phase": "Analyze", "problem_statement": "The display module bonding process has a low yield, contributing significantly to COPQ. Root cause is unknown.", "goal_statement": "Identify and control significant factors in the bonding process to increase yield from 88% to 98% by EOY.", "team": ["Sofia Chen (Lead)", "David Lee (Engineer)"], "start_date": base_date + timedelta(days=200)}
    ]

    # --- 5. Generate Enriched Product Release Data ---
    release_batches = []
    failure_modes = ["Component Failure", "Assembly Error", "Calibration Drift", "Cosmetic Defect"]
    failure_costs = {"Component Failure": 1200, "Assembly Error": 450, "Calibration Drift": 250, "Cosmetic Defect": 150}
    for i in range(150):
        batch_id = f"BATCH-{202400 + i}"
        is_fail = random.random() < 0.08
        measurement = np.random.normal(10.8, 0.8) if is_fail else np.random.normal(10.0, 0.2)
        failure_category = random.choice(failure_modes) if is_fail else None
        cost = failure_costs.get(failure_category, 0) if is_fail else 0
        release_batches.append({
            "batch_id": batch_id, "product_line": "IntelliVue Patient Monitor", "site": "Eindhoven, NL",
            "lot_size": 1000, "test_measurement": measurement,
            "true_status": "Fail" if is_fail else "Pass",
            "failure_category": failure_category, "copq": cost
        })
    
    # --- 6. Kaizen & Training Data ---
    kaizen_events = [
        {"id": "KZN-01", "site": "Eindhoven, NL", "date": base_date + timedelta(days=250), "title": "5S Implementation on Monitor Assembly Line 3", "outcome": "Reduced tool search time by 60%; cleared 25 sq. meters of floor space.", "team": ["Maria Rodriguez", "David Lee"]},
        {"id": "KZN-02", "site": "Andover, US", "date": base_date + timedelta(days=300), "title": "Value Stream Mapping of Defibrillator Sub-assembly", "outcome": "Identified 3 non-value-add steps, reducing process cycle time by 15%.", "team": ["John Smith", "Jane Doe"]}
    ]
    training_materials = [
        {"id": "TRN-001", "title": "Introduction to DMAIC Methodology", "type": "eLearning", "duration_hr": 4, "link": "#", "target_audience": "All"},
        {"id": "TRN-002", "title": "Statistical Process Control (SPC) Fundamentals", "type": "PDF Guide", "duration_hr": 2, "link": "#", "target_audience": "Engineers, Technicians"},
        {"id": "TRN-003", "title": "Design of Experiments (DOE) Workshop", "type": "Workshop Slides", "duration_hr": 8, "link": "#", "target_audience": "Engineers"},
        {"id": "TRN-004", "title": "Root Cause Analysis (Fishbone & 5 Whys)", "type": "eLearning", "duration_hr": 2, "link": "#", "target_audience": "All"},
    ]
    
    # --- 7. Generate Predictive Quality Data ---
    predictive_data = []
    for _ in range(500):
        temp = np.random.normal(200, 10)
        pressure = np.random.normal(50, 5)
        vibration = np.random.normal(1.5, 0.5)
        fail_prob = 1 / (1 + np.exp(-(0.1 * (temp - 210) + 0.5 * (pressure - 52))))
        outcome = "Fail" if random.random() < fail_prob else "Pass"
        predictive_data.append({"in_process_temp": temp, "in_process_pressure": pressure, "in_process_vibration": vibration, "final_qc_outcome": outcome})

    # --- Assemble Final Data Model ---
    return {
        "data_version": version, "global_kpis": kpi_data,
        "process_data": {
            "source_product": "IntelliVue Patient Monitor", "source_site": "Eindhoven, NL",
            "specs": {"voltage_a": {"lsl": 4.9, "usl": 5.1}, "pressure_b": {"lsl": 95, "usl": 105}, "seal_temperature": {"lsl": 147, "usl": 153}},
            "data": process_data_df
        },
        "dmaic_projects": dmaic_projects,
        "doe_data": doe_df, # New sophisticated DOE/RSM data
        "release_data": release_batches, "kaizen_events": kaizen_events,
        "training_materials": training_materials,
        "predictive_quality_data": pd.DataFrame(predictive_data)
    }

class SessionStateManager:
    _DATA_KEY = "six_sigma_quality_data"
    _CURRENT_DATA_VERSION = 2 # Incremented version for the new data model

    def __init__(self):
        session_data = st.session_state.get(self._DATA_KEY)
        if not session_data or session_data.get("data_version") != self._CURRENT_DATA_VERSION:
            logger.info(f"Initializing session state with Quality Optimizer data model v{self._CURRENT_DATA_VERSION}.")
            try:
                st.session_state[self._DATA_KEY] = _create_quality_optimizer_model(self._CURRENT_DATA_VERSION)
                logger.info("Session state initialized successfully.")
            except Exception as e:
                logger.critical(f"FATAL: Data generation failed: {e}", exc_info=True)
                st.error(f"A critical error occurred during application startup: {e}. The application cannot continue.", icon="🚨")
                st.stop()

    def get_data(self, primary_key: str, secondary_key: Optional[str] = None) -> Any:
        try:
            data_store = st.session_state.get(self._DATA_KEY, {})
            if secondary_key:
                return data_store.get(primary_key, {}).get(secondary_key, [])
            else:
                return data_store.get(primary_key, {})
        except (KeyError, AttributeError):
            logger.warning(f"Attempted to access non-existent key: '{primary_key}/{secondary_key}'")
            return {} if secondary_key is None else []

    def update_data(self, data: Any, primary_key: str, secondary_key: Optional[str] = None) -> None:
        try:
            if self._DATA_KEY not in st.session_state: st.session_state[self._DATA_KEY] = {}
            if secondary_key:
                if primary_key not in st.session_state[self._DATA_KEY]: st.session_state[self._DATA_KEY][primary_key] = {}
                st.session_state[self._DATA_KEY][primary_key][secondary_key] = data
            else:
                st.session_state[self._DATA_KEY][primary_key] = data
            logger.info(f"Session state updated for {primary_key}.{secondary_key or ''}")
        except Exception as e:
            logger.error(f"Failed to update session state for {primary_key}/{secondary_key}: {e}", exc_info=True)
            st.error("A critical error occurred while trying to save data. Please refresh the page.")
